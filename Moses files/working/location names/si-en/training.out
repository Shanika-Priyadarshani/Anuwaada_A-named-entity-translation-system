nohup: ignoring input
Using SCRIPTS_ROOTDIR: /home/anuadmin/moses/mosesdecoder/scripts
Using single-thread GIZA
using pigz 
(1) preparing corpus @ Fri Nov 22 20:54:45 +0530 2019
Executing: mkdir -p /home/anuadmin/moses/working/train/corpus
(1.0) selecting factors @ Fri Nov 22 20:54:45 +0530 2019
(1.1) running mkcls  @ Fri Nov 22 20:54:45 +0530 2019
/home/anuadmin/moses/mosesdecoder/tools/mkcls -c50 -n2 -p/home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.si -V/home/anuadmin/moses/working/train/corpus/si.vcb.classes opt
  /home/anuadmin/moses/working/train/corpus/si.vcb.classes already in place, reusing
(1.1) running mkcls  @ Fri Nov 22 20:54:45 +0530 2019
/home/anuadmin/moses/mosesdecoder/tools/mkcls -c50 -n2 -
***** 2 runs. (algorithm:TA)*****
;KategProblem:cats: 50   words: 981

start-costs: MEAN: 4.18442e+06 (4.17447e+06-4.19437e+06)  SIGMA:9951.76   
  end-costs: MEAN: 4.02996e+06 (4.02924e+06-4.03069e+06)  SIGMA:729.068   
   start-pp: MEAN: 47.046 (45.6723-48.4198)  SIGMA:1.37376   
     end-pp: MEAN: 29.8856 (29.8217-29.9496)  SIGMA:0.0639501   
 iterations: MEAN: 27206 (27109-27303)  SIGMA:97   
       time: MEAN: 1.30539 (1.30506-1.30571)  SIGMA:0.0003215   
(1.1) running mkcls  @ Fri Nov 22 20:55:08 +0530 2019
/home/anuadmin/moses/mosesdecoder/tools/mkcls -c50 -n2 -p/home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.en -V/home/anuadmin/moses/working/train/corpus/en.vcb.classes opt
  /home/anuadmin/moses/working/train/corpus/en.vcb.classes already in place, reusing
(1.2) creating vcb file /home/anuadmin/moses/working/train/corpus/si.vcb @ Fri Nov 22 20:55:08 +0530 2019
(1.2) creating vcb file /home/anuadmin/moses/working/train/corpus/en.vcb @ Fri Nov 22 20:55:09 +0530 2019
(1.3) numberizing corpus /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt @ Fri Nov 22 20:55:10 +0530 2019
  /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt already in place, reusing
(1.3) numberizing corpus /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt @ Fri Nov 22 20:55:10 +0530 2019
  /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt already in place, reusing
(2) running giza @ Fri Nov 22 20:55:10 +0530 2019
(2.1a) running snt2cooc si-en @ Fri Nov 22 20:55:10 +0530 2019

Executing: mkdir -p /home/anuadmin/moses/working/train/giza.si-en
Executing: /home/anuadmin/moses/mosesdecoder/tools/snt2cooc.out /home/anuadmin/moses/working/train/corpus/en.vcb /home/anuadmin/moses/working/train/corpus/si.vcb /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt > /home/anuadmin/moses/working/train/giza.si-en/si-en.cooc
/home/anuadmin/moses/mosesdecoder/tools/snt2cooc.out /home/anuadmin/moses/working/train/corpus/en.vcb /home/anuadmin/moses/working/train/corpus/si.vcb /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt > /home/anuadmin/moses/working/train/giza.si-en/si-en.cooc
line 1000
line 2000
line 3000
line 4000
line 5000
line 6000
line 7000
line 8000
line 9000
line 10000
line 11000
line 12000
line 13000
line 14000
line 15000
line 16000
line 17000
line 18000
line 19000
line 20000
line 21000
line 22000
line 23000
liline 40000
line 41000
line 42000
line 43000
line 44000
line 4500line 30(2.1b) running line 32000
line 33000
line 34000
line 35000
line 36000
line 37000
line 38000
line 39000
line 40000
line 41000
line 42000
line 43000
line 44000
line 45000
END.
(2.1b) running giza si-en @ Fri Nov 22 20:55:12 +0530 2019
/home/anuadmin/moses/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/anuadmin/moses/working/train/giza.si-en/si-en.cooc -c /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/anuadmin/moses/working/train/giza.si-en/si-en -onlyaldumps 1 -p0 0.999 -s /home/anuadmin/moses/working/train/corpus/en.vcb -t /home/anuadmin/moses/working/train/corpus/si.vcb
Executing: /home/anuadmin/moses/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/anuadmin/moses/working/train/giza.si-en/si-en.cooc -c /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/anuadmin/moses/working/train/giza.si-en/si-en -onlyaldumps 1 -p0 0.999 -s /home/anuadmin/moses/working/train/corpus/en.vcb -t /home/anuadmin/moses/working/train/corpus/si.vcb
/home/anuadmin/moses/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/anuadmin/moses/working/train/giza.si-en/si-en.cooc -c /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/anuadmin/moses/working/train/giza.si-en/si-en -onlyaldumps 1 -p0 0.999 -s /home/anuadmin/moses/working/train/corpus/en.vcb -t /home/anuadmin/moses/working/train/corpus/si.vcb
Parameter 'coocurrencefile' changed from '' to '/home/anuadmin/moses/working/train/giza.si-en/si-en.cooc'
Parameter 'c' changed from '' to '/home/anuadmin/moses/working/train/corpus/si-en-int-train.snt'
Parameter 'm3' changed from '5' to '3'
Parameter 'm4' changed from '5' to '3'
Parameter 'model1dumpfrequency' changed from '0' to '1'
Parameter 'model4smoothfactor' changed from '0.2' to '0.4'
Parameter 'nodumps' changed from '0' to '1'
Parameter 'nsmooth' changed from '64' to '4'
Parameter 'o' changed from '119-11-22.205512.anuadmin' to '/home/anuadmin/moses/working/train/giza.si-en/si-en'
Parameter 'onlyaldumps' changed from '0' to '1'
Parameter 'p0' changed from '-1' to '0.999'
Parameter 's' changed from '' to '/home/anuadmin/moses/working/train/corpus/en.vcb'
Parameter 't' changed from '' to '/home/anuadmin/moses/working/train/corpus/si.vcb'
general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 119-11-22.205512.anuadmin.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/anuadmin/moses/working/train/giza.si-en/si-en  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/anuadmin/moses/working/train/corpus/en.vcb  (source vocabulary file name)
t = /home/anuadmin/moses/working/train/corpus/si.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 119-11-22.205512.anuadmin.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/anuadmin/moses/working/train/giza.si-en/si-en  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/anuadmin/moses/working/train/corpus/en.vcb  (source vocabulary file name)
t = /home/anuadmin/moses/working/train/corpus/si.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

reading vocabulary files 
Reading vocabulary file from:/home/anuadmin/moses/working/train/corpus/en.vcb
Reading vocabulary file from:/home/anuadmin/moses/working/train/corpus/si.vcb
Source vocabulary list has 874 unique tokens 
Target vocabulary list has 983 unique tokens 
Calculating vocabulary frequencies from corpus /home/anuadmin/moses/working/train/corpus/si-en-int-train.snt
Reading more sentence pairs into memory ... 
WARNING: The following sentence pair has source/target sentence length ration more than
the maximum allowed limit for a source word fertCorpus fits in memory, corpus has: 45500 sentence pairs.
 Train total # sentence pairs (weighted): 45500
Size of source portion of the training corpus: 546575 tokens
Size of Corpus fits in memory, corpus has: 45500 sentence pairs.
 Train total # sentence pairs (weighted): 45500
Size of source portion of the training corpus: 546575 tokens
Size of the target portion of the training corpus: 295203 tokens 
In source portion of the training corpus, only 873 unique tokens appeared
In target portion of the training corpus, only 980 unique tokens appeared
lambda for PP calculation in IBM-1,IBM-2,HMM:= 295203/(592075-45500)== 0.540096
There are 29964 29964 entries in table
==========================================================
Model1 Training Started at: Fri Nov 22 20:55:14 2019

-----------
Model1: Iteration 1
Model1: (1) TRAIN CROSS-ENTROPY 10.8325 PERPLEXITY 1823.47
Model1: (1) VITERBI TRAIN CROSS-ENTROPY 14.5943 PERPLEXITY 24735.9
Model 1 Iteration: 1 took: 4 seconds
-----------
Model1: Iteration 2
Model1: (2) TRAIN CROSS-ENTROPY 7.04998 PERPLEXITY 132.512
Model1: (2) VITERBI TRAIN CROSS-ENTROPY 9.59072 PERPLEXITY 771.073
Model 1 Iteration: 2 took: 3 seconds
-----------
Model1: Iteration 3
Model1: (3) TRAIN CROSS-ENTROPY 6.73888 PERPLEXITY 106.808
Model1: (3) VITERBI TRAIN CROSS-ENTROPY 8.60675 PERPLEXITY 389.842
Model 1 Iteration: 3 took: 3 seconds
-----------
Model1: Iteration 4
Model1: (4) TRAIN CROSS-ENTROPY 6.54145 PERPLEXITY 93.1481
Model1: (4) VITERBI TRAIN CROSS-ENTROPY 8.03991 PERPLEXITY 263.181
Model 1 Iteration: 4 took: 3 seconds
-----------
Model1: Iteration 5
Model1: (5) TRAIN CROSS-ENTROPY 6.43515 PERPLEXITY 86.5312
Model1: (5) VITERBI TRAIN CROSS-ENTROPY 7.73415 PERPLEXITY 212.917
Model 1 Iteration: 5 took: 3 seconds
Entire Model1 Training took: 16 seconds
NOTE: I am doing iterations with the HMM model!
Read classes: #wo-----------
Hmm: Iteration 1
A/D table contains 28360 parameters.
Hmm: (1) TRAIN CROSS-ENTROPY 6.38089 PERPLEXITY 83.3371
Hmm: (1) VITERBI TRAIN CROSS-ENTROPY 7.56861 PERPLEX-----------
Hmm: Iteration 1
A/D table contains -----------
Hmm: Iteration 2
A/D table contains 28360 parameters.
Hmm: (2) TRAIN CROSS-ENTROPY 5.42859 PERPLEXITY 43.0694
Hmm: (2) VITERBI TRAIN CROSS-ENTROPY 5.90058 PERPLEX-----------
Hmm: Iteration 2
A/D table contains -----------
Hmm: Iteration 3
A/D table contains 28360 parameters.
Hmm: (3) TRAIN CROSS-ENTROPY 4.73911 PERPLEXITY 26.7064
Hmm: (3) VITERBI TRAIN CROSS-ENTROPY 5.01051 PERPLEX-----------
Hmm: Iteration 3
A/D table contains-----------
Hmm: Iteration 4
A/D table contains 28360 parameters.
Hmm: (4) TRAIN CROSS-ENTROPY 4.54847 PERPLEXITY 23.4006
Hmm: (4) VITERBI TRAIN CROSS-ENTROPY 4.76067 PERPLEX-----------
Hmm: Iteration 4
A/D table contains -----------
Hmm: Iteration 5
A/D table contains 28360 parameters.
Hmm: (5) TRAIN CROSS-ENTROPY 4.49085 PERPLEXITY 22.4843
Hmm: (5) VITERBI TRAIN CROSS-ENTROPY 4.67739 PERPLEX-----------
Hmm: Iteration 5
A/D table contains 28360 parameters.
Hmm: (5) TRAIN CROSS-ENTROPY 4.49085 PERPLEXITY 22.4843
Hmm: (5) VITERBI TRAIN CROSS-ENTROPY 4.67739 PERPLEXITY 25.5879

Hmm Iteration: 5 took: 39 seconds

Entire Hmm Training took: 181 seconds
==========================================================
Read classes: #words: 873  #classes: 51
Read classes: #words: 982  #classes: 51
Read classes: #words: 873  #classes: 51
Read classes: #words: 982  #classes: 51

===============================30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.262 #alsophisticatedcountcollection: 0 #hcsteps: 0
#peggingImprovements: 0
A/D table contains 28360 parameters.
A/D tabl40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.262 #alsophisticatedcountcollection: 0 #hcsteps: 0
#peggingImprovements: 0
A/D table contains 28360 parameters.
A/D table contains 18600 parameters.
NTable contains 8740 parameter.
p0_count is 270588 and p1 is 12067.4; p0 is 0.999 p1: 0.001
THTo3: TRAIN CROSS-ENTROPY 3.6313 PERPLEXITY 130000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.428 #alsophisticatedcountcollection: 0 #hcsteps: 1.78147
#peggingImprovements: 0
A/D table contains 28360 parameters.
A/40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.428 #alsophisticatedcountcollection: 0 #hcsteps: 1.78147
#peggingImprovements: 0
A/D table contains 28360 parameters.
A/D table contains 19639 parameters.
NTable contains 8740 parameter.
p0_count is 287709 and p1 is 3746.99; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 4.8927 PERPLEXITY 29.30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.436 #alsophisticatedcountcollection: 0 #hcsteps: 1.74607
#peggingImprovements: 0
A/D table contains 28360 parameters.
A/40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.436 #alsophisticatedcountcollection: 0 #hcsteps: 1.74607
#peggingImprovements: 0
A/D table contains 28360 parameters.
A/D table contains 19639 parameters.
NTable contains 8740 parameter.
p0_count is 288822 and p1 is 3190.5; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 4.73016 PERPLEX20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.469 #alsophisticatedcountcollection: 23.5558 #hcsteps: 1.72218
#peggingImprovements: 0
D4 table contains 471975 paramete40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.469 #alsophisticatedcountcollection: 23.5558 #hcsteps: 1p0_count is 289242 and p1 is 2980.75; p0 is 0.999 p1: 0.001
T3To4: TRAIN CROSS-ENTROPY 4.66324 PERPLEXITY 25.3382
T3To4: (4) TRAIN VITERBI CROSS-ENTROPY 4.73291 PERPLEXITY 26p0_count is 289242 and p1 is 2980.75; p0 is 0.999 p1: 0.001
T3To4: TRAIN CROSS-ENTROPY 4.66324 PERPLE20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.436 #alsophisticatedcountcollection: 17.1385 #hcsteps: 1.58837
#peggingImprovements: 0
D4 table contains 471975 parameters.
A/#centers(pre/hillclimbed/real): 1 1 1  #al: 107.436 #alsophisticatedcountcollection: 17.1385 #hcsteps: 1p0_count is 290167 and p1 is 2518.25; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 4.53586 PERPLEXITY 23.1969
Model4: (5) TRAIN VITERBI CROSS-ENTROPY 4.58938 PERPLEXITY p0_count is 290167 and p1 is 2518.25; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 4.53586 PERPLEXI20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 107.423 #alsophisticatedcountcollection: 15.7612 #hcsteps: 1.54174
#peggingImprovements: 0
D4 table contains 472178 parameters.
A/#centers(pre/hillclimbed/real): 1 1 1  #al: 107.423 #alsophisticatedcountcollection: 15.7612 #hcsteps: 1.54174
#peggingImprovements: 0
D4 table contains 472178 parameters.
A/D table contains 28360 parameters.
A/D table contains 22448 parameters.
NTable contains 8740 parameter.
p0_count is 290666 and p1 is 2268.47; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 4.44039 PERPLEXITY 21.7116
Model4: (6) TRAIN VITERBI CROSS-ENTROPY 4.4832 PERPLEXITY 22.3654

Model4 Viterbi Iteration : 6 took: 67 seconds
H333444 Training Finished at: Fri Nov 22 21:02:41 2019


Entire Viterbi H333444 Training took: 249 seconds
==========================================================

Entire Training took: 449 seconds
Program Finished at: Fri Nov 22 21:02:41 2019

==========================================================
ERROR: Giza did not produce the output file /home/anuadmin/moses/working/train/giza.si-en/si-en.A3.final. Is your corpus clean (reasonably-sized sentences)? at /home/anuadmin/moses/mosesdecoder/scripts/training/train-model.perl line 1338.
in/moses/working/train/corpus/en.vcb /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt > /home/anuadmin/moses/working/train/giza.en-si/en-si.cooc
/home/anuadmin/moses/mosesdecoder/tools/snt2cooc.out /home/anuadmin/moses/working/train/corpus/si.vcb /home/anuadmin/moses/working/train/corpus/en.vcb /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt > /home/anuadmin/moses/working/train/giza.en-si/en-si.cooc
line 1000
line 2000
line 3000
line 4000
line 5000
line 6000
line 7000
line 8000
line 9000
line 10000
line 11000
line 12000
line 13000
line 14000
line 15000
line 16000
line 17000
line 18000
line 19000
line 20000
line 21000
line 22000
line 23000
line 24000
line 25000
line 26000
line 27000
line 28000
line 29000
line 30000
line 31000
line 32000
line 33000
line 34000
line 35000
line 36000
line 37000
line 38000
line 39000
line 40000
line 41000
line 42000
line 43000
line 44000
line 45000
END.
(2.1b) running giza en-si @ Fri Nov 22 21:02:38 +0530 2019
/home/anuadmin/moses/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/anuadmin/moses/working/train/giza.en-si/en-si.cooc -c /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/anuadmin/moses/working/train/giza.en-si/en-si -onlyaldumps 1 -p0 0.999 -s /home/anuadmin/moses/working/train/corpus/si.vcb -t /home/anuadmin/moses/working/train/corpus/en.vcb
Executing: /home/anuadmin/moses/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/anuadmin/moses/working/train/giza.en-si/en-si.cooc -c /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/anuadmin/moses/working/train/giza.en-si/en-si -onlyaldumps 1 -p0 0.999 -s /home/anuadmin/moses/working/train/corpus/si.vcb -t /home/anuadmin/moses/working/train/corpus/en.vcb
/home/anuadmin/moses/mosesdecoder/tools/GIZA++  -CoocurrenceFile /home/anuadmin/moses/working/train/giza.en-si/en-si.cooc -c /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt -m1 5 -m2 0 -m3 3 -m4 3 -model1dumpfrequency 1 -model4smoothfactor 0.4 -nodumps 1 -nsmooth 4 -o /home/anuadmin/moses/working/train/giza.en-si/en-si -onlyaldumps 1 -p0 0.999 -s /home/anuadmin/moses/working/train/corpus/si.vcb -t /home/anuadmin/moses/working/train/corpus/en.vcb
Parameter 'coocurrencefile' changed from '' to '/home/anuadmin/moses/working/train/giza.en-si/en-si.cooc'
Parameter 'c' changed from '' to '/home/anuadmin/moses/working/train/corpus/en-si-int-train.snt'
Parameter 'm3' changed from '5' to '3'
Parameter 'm4' changed from '5' to '3'
Parameter 'model1dumpfrequency' changed from '0' to '1'
Parameter 'model4smoothfactor' changed from '0.2' to '0.4'
Parameter 'nodumps' changed from '0' to '1'
Parameter 'nsmooth' changed from '64' to '4'
Parameter 'o' changed from '119-11-22.210238.anuadmin' to '/home/anuadmin/moses/working/train/giza.en-si/en-si'
Parameter 'onlyaldumps' changed from '0' to '1'
Parameter 'p0' changed from '-1' to '0.999'
Parameter 's' changed from '' to '/home/anuadmin/moses/working/train/corpus/si.vcb'
Parameter 't' changed from '' to '/home/anuadmin/moses/working/train/corpus/en.vcb'
general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 119-11-22.210238.anuadmin.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/anuadmin/moses/working/train/giza.en-si/en-si  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/anuadmin/moses/working/train/corpus/si.vcb  (source vocabulary file name)
t = /home/anuadmin/moses/working/train/corpus/en.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

general parameters:
-------------------
ml = 101  (maximum sentence length)

No. of iterations:
-------------------
hmmiterations = 5  (mh)
model1iterations = 5  (number of iterations for Model 1)
model2iterations = 0  (number of iterations for Model 2)
model3iterations = 3  (number of iterations for Model 3)
model4iterations = 3  (number of iterations for Model 4)
model5iterations = 0  (number of iterations for Model 5)
model6iterations = 0  (number of iterations for Model 6)

parameter for various heuristics in GIZA++ for efficient training:
------------------------------------------------------------------
countincreasecutoff = 1e-06  (Counts increment cutoff threshold)
countincreasecutoffal = 1e-05  (Counts increment cutoff threshold for alignments in training of fertility models)
mincountincrease = 1e-07  (minimal count increase)
peggedcutoff = 0.03  (relative cutoff probability for alignment-centers in pegging)
probcutoff = 1e-07  (Probability cutoff threshold for lexicon probabilities)
probsmooth = 1e-07  (probability smoothing (floor) value )

parameters for describing the type and amount of output:
-----------------------------------------------------------
compactalignmentformat = 0  (0: detailled alignment format, 1: compact alignment format )
hmmdumpfrequency = 0  (dump frequency of HMM)
l = 119-11-22.210238.anuadmin.log  (log file name)
log = 0  (0: no logfile; 1: logfile)
model1dumpfrequency = 1  (dump frequency of Model 1)
model2dumpfrequency = 0  (dump frequency of Model 2)
model345dumpfrequency = 0  (dump frequency of Model 3/4/5)
nbestalignments = 0  (for printing the n best alignments)
nodumps = 1  (1: do not write any files)
o = /home/anuadmin/moses/working/train/giza.en-si/en-si  (output file prefix)
onlyaldumps = 1  (1: do not write any files)
outputpath =   (output path)
transferdumpfrequency = 0  (output: dump of transfer from Model 2 to 3)
verbose = 0  (0: not verbose; 1: verbose)
verbosesentence = -10  (number of sentence for which a lot of information should be printed (negative: no output))

parameters describing input files:
----------------------------------
c = /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt  (training corpus file name)
d =   (dictionary file name)
s = /home/anuadmin/moses/working/train/corpus/si.vcb  (source vocabulary file name)
t = /home/anuadmin/moses/working/train/corpus/en.vcb  (target vocabulary file name)
tc =   (test corpus file name)

smoothing parameters:
---------------------
emalsmooth = 0.2  (f-b-trn: smoothing factor for HMM alignment model (can be ignored by -emSmoothHMM))
model23smoothfactor = 0  (smoothing parameter for IBM-2/3 (interpolation with constant))
model4smoothfactor = 0.4  (smooting parameter for alignment probabilities in Model 4)
model5smoothfactor = 0.1  (smooting parameter for distortion probabilities in Model 5 (linear interpolation with constant))
nsmooth = 4  (smoothing for fertility parameters (good value: 64): weight for wordlength-dependent fertility parameters)
nsmoothgeneral = 0  (smoothing for fertility parameters (default: 0): weight for word-independent fertility parameters)

parameters modifying the models:
--------------------------------
compactadtable = 1  (1: only 3-dimensional alignment table for IBM-2 and IBM-3)
deficientdistortionforemptyword = 0  (0: IBM-3/IBM-4 as described in (Brown et al. 1993); 1: distortion model of empty word is deficient; 2: distoriton model of empty word is deficient (differently); setting this parameter also helps to avoid that during IBM-3 and IBM-4 training too many words are aligned with the empty word)
depm4 = 76  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
depm5 = 68  (d_{=1}: &1:l, &2:m, &4:F, &8:E, d_{>1}&16:l, &32:m, &64:F, &128:E)
emalignmentdependencies = 2  (lextrain: dependencies in the HMM alignment model.  &1: sentence length; &2: previous class; &4: previous position;  &8: French position; &16: French class)
emprobforempty = 0.4  (f-b-trn: probability for empty word)

parameters modifying the EM-algorithm:
--------------------------------------
m5p0 = -1  (fixed value for parameter p_0 in IBM-5 (if negative then it is determined in training))
manlexfactor1 = 0  ()
manlexfactor2 = 0  ()
manlexmaxmultiplicity = 20  ()
maxfertility = 10  (maximal fertility for fertility models)
p0 = 0.999  (fixed value for parameter p_0 in IBM-3/4 (if negative then it is determined in training))
pegging = 0  (0: no pegging; 1: do pegging)

reading vocabulary files 
Reading vocabulary file from:/home/anuadmin/moses/working/train/corpus/si.vcb
Reading vocabulary file from:/home/anuadmin/moses/working/train/corpus/en.vcb
Source vocabulary list has 983 unique tokens 
Target vocabulary list has 874 unique tokens 
Calculating vocabulary frequencies from corpus /home/anuadmin/moses/working/train/corpus/en-si-int-train.snt
Reading more sentence pairs into memory ... 
Corpus fits in memory, corpus has: 45500 sentence pairs.
 Train total # sentence pairs (weighted): 45500
Size of source portion of the training corpus: 295213 tokens
Size of the target portion of the training corpus: 546575 tokens 
In source portion of the training corpus, only 981 unique tokens appeared
In target portion of the training corpus, only 872 unique tokens appeared
lambda for PP calculation in IBM-1,IBM-2,HMM:= 546575/(340713-45500)== 1.85146
There are 29856 29856 entries in table
==========================================================
Model1 Training Started at: Fri Nov 22 21:02:40 2019

-----------
Model1: Iteration 1
Model1: (1) TRAIN CROSS-ENTROPY 10.2257 PERPLEXITY 1197.43
Model1: (1) VITERBI TRAIN CROSS-ENTROPY 13.1874 PERPLEXITY 9328.2
Model 1 Iteration: 1 took: 2 seconds
-----------
Model1: Iteration 2
Model1: (2) TRAIN CROSS-ENTROPY 4.17156 PERPLEXITY 18.0204
Model1: (2) VITERBI TRAIN CROSS-ENTROPY 6.27918 PERPLEXITY 77.6643
Model 1 Iteration: 2 took: 3 seconds
-----------
Model1: Iteration 3
Model1: (3) TRAIN CROSS-ENTROPY 3.93691 PERPLEXITY 15.3154
Model1: (3) VITERBI TRAIN CROSS-ENTROPY 5.56344 PERPLEXITY 47.2893
Model 1 Iteration: 3 took: 3 seconds
-----------
Model1: Iteration 4
Model1: (4) TRAIN CROSS-ENTROPY 3.79457 PERPLEXITY 13.8765
Model1: (4) VITERBI TRAIN CROSS-ENTROPY 5.14038 PERPLEXITY 35.2703
Model 1 Iteration: 4 took: 1 seconds
-----------
Model1: Iteration 5
Model1: (5) TRAIN CROSS-ENTROPY 3.71668 PERPLEXITY 13.1472
Model1: (5) VITERBI TRAIN CROSS-ENTROPY 4.86754 PERPLEXITY 29.1929
Model 1 Iteration: 5 took: 1 seconds
Entire Model1 Training took: 10 seconds
NOTE: I am doing iterations with the HMM model!
Read classes: #words: 982  #classes: 51
Read classes: #words: 873  #classes: 51

==========================================================
Hmm Training Started at: Fri Nov 22 21:02:50 2019

-----------
Hmm: Iteration 1
A/D table contains 23226 parameters.
Hmm: (1) TRAIN CROSS-ENTROPY 3.67489 PERPLEXITY 12.7718
Hmm: (1) VITERBI TRAIN CROSS-ENTROPY 4.69946 PERPLEXITY 25.9824

Hmm Iteration: 1 took: 15 seconds

-----------
Hmm: Iteration 2
A/D table contains 23226 parameters.
Hmm: (2) TRAIN CROSS-ENTROPY 3.23405 PERPLEXITY 9.40906
Hmm: (2) VITERBI TRAIN CROSS-ENTROPY 3.74055 PERPLEXITY 13.3665

Hmm Iteration: 2 took: 18 seconds

-----------
Hmm: Iteration 3
A/D table contains 23226 parameters.
Hmm: (3) TRAIN CROSS-ENTROPY 2.87896 PERPLEXITY 7.35618
Hmm: (3) VITERBI TRAIN CROSS-ENTROPY 3.20454 PERPLEXITY 9.21855

Hmm Iteration: 3 took: 16 seconds

-----------
Hmm: Iteration 4
A/D table contains 23226 parameters.
Hmm: (4) TRAIN CROSS-ENTROPY 2.709 PERPLEXITY 6.53867
Hmm: (4) VITERBI TRAIN CROSS-ENTROPY 2.9658 PERPLEXITY 7.81258

Hmm Iteration: 4 took: 18 seconds

-----------
Hmm: Iteration 5
A/D table contains 23226 parameters.
Hmm: (5) TRAIN CROSS-ENTROPY 2.65082 PERPLEXITY 6.28024
Hmm: (5) VITERBI TRAIN CROSS-ENTROPY 2.87844 PERPLEXITY 7.35355

Hmm Iteration: 5 took: 18 seconds

Entire Hmm Training took: 85 seconds
==========================================================
Read classes: #words: 982  #classes: 51
Read classes: #words: 873  #classes: 51
Read classes: #words: 982  #classes: 51
Read classes: #words: 873  #classes: 51

==========================================================
Starting H333444:  Viterbi Training
 H333444 Training Started at: Fri Nov 22 21:04:15 2019


---------------------
THTo3: Iteration 1
10000
20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 154.034 #alsophisticatedcountcollection: 0 #hcsteps: 0
#peggingImprovements: 0
A/D table contains 23226 parameters.
A/D table contains 28036 parameters.
NTable contains 9830 parameter.
p0_count is 287567 and p1 is 128420; p0 is 0.999 p1: 0.001
THTo3: TRAIN CROSS-ENTROPY 2.26609 PERPLEXITY 4.81018
THTo3: (1) TRAIN VITERBI CROSS-ENTROPY 2.3985 PERPLEXITY 5.27254

THTo3 Viterbi Iteration : 1 took: 26 seconds

---------------------
Model3: Iteration 2
10000
20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 155.891 #alsophisticatedcountcollection: 0 #hcsteps: 3.69934
#peggingImprovements: 0
A/D table contains 23226 parameters.
A/D table contains 28079 parameters.
NTable contains 9830 parameter.
p0_count is 454843 and p1 is 45865.9; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 4.04209 PERPLEXITY 16.4737
Model3: (2) TRAIN VITERBI CROSS-ENTROPY 4.17792 PERPLEXITY 18.1001

Model3 Viterbi Iteration : 2 took: 22 seconds

---------------------
Model3: Iteration 3
10000
20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 155.446 #alsophisticatedcountcollection: 0 #hcsteps: 4.05767
#peggingImprovements: 0
A/D table contains 23226 parameters.
A/D table contains 28259 parameters.
NTable contains 9830 parameter.
p0_count is 510874 and p1 is 17850.4; p0 is 0.999 p1: 0.001
Model3: TRAIN CROSS-ENTROPY 3.52758 PERPLEXITY 11.5321
Model3: (3) TRAIN VITERBI CROSS-ENTROPY 3.62227 PERPLEXITY 12.3144

Model3 Viterbi Iteration : 3 took: 22 seconds

---------------------
T3To4: Iteration 4
10000
20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 155.429 #alsophisticatedcountcollection: 40.664 #hcsteps: 4.12415
#peggingImprovements: 0
D4 table contains 420819 parameters.
A/D table contains 23226 parameters.
A/D table contains 28259 parameters.
NTable contains 9830 parameter.
p0_count is 521156 and p1 is 12709.7; p0 is 0.999 p1: 0.001
T3To4: TRAIN CROSS-ENTROPY 3.41563 PERPLEXITY 10.671
T3To4: (4) TRAIN VITERBI CROSS-ENTROPY 3.49308 PERPLEXITY 11.2595

T3To4 Viterbi Iteration : 4 took: 46 seconds

---------------------
Model4: Iteration 5
10000
20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 155.251 #alsophisticatedcountcollection: 24.9097 #hcsteps: 4.00582
#peggingImprovements: 0
D4 table contains 420819 parameters.
A/D table contains 23226 parameters.
A/D table contains 28486 parameters.
NTable contains 9830 parameter.
p0_count is 520610 and p1 is 12982.5; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 3.05234 PERPLEXITY 8.29557
Model4: (5) TRAIN VITERBI CROSS-ENTROPY 3.09368 PERPLEXITY 8.5367

Model4 Viterbi Iteration : 5 took: 198 seconds

---------------------
Model4: Iteration 6
10000
20000
30000
40000
#centers(pre/hillclimbed/real): 1 1 1  #al: 155.189 #alsophisticatedcountcollection: 19.6407 #hcsteps: 3.97473
#peggingImprovements: 0
D4 table contains 421225 parameters.
A/D table contains 23226 parameters.
A/D table contains 28486 parameters.
NTable contains 9830 parameter.
p0_count is 519641 and p1 is 13466.8; p0 is 0.999 p1: 0.001
Model4: TRAIN CROSS-ENTROPY 2.91141 PERPLEXITY 7.52351
Model4: (6) TRAIN VITERBI CROSS-ENTROPY 2.94527 PERPLEXITY 7.70222

Model4 Viterbi Iteration : 6 took: 255 seconds
H333444 Training Finished at: Fri Nov 22 21:13:44 2019


Entire Viterbi H333444 Training took: 569 seconds
==========================================================

Entire Training took: 667 seconds
Program Finished at: Fri Nov 22 21:13:45 2019

==========================================================
Executing: rm -f /home/anuadmin/moses/working/train/giza.en-si/en-si.A3.final.gz
Executing: pigz /home/anuadmin/moses/working/train/giza.en-si/en-si.A3.final
(3) generate word alignment @ Fri Nov 22 21:13:49 +0530 2019
Combining forward and inverted alignment from files:
  /home/anuadmin/moses/working/train/giza.si-en/si-en.A3.final.{bz2,gz}
  /home/anuadmin/moses/working/train/giza.en-si/en-si.A3.final.{bz2,gz}
Executing: mkdir -p /home/anuadmin/moses/working/train/model
Executing: /home/anuadmin/moses/mosesdecoder/scripts/training/giza2bal.pl -d "pigz -cd /home/anuadmin/moses/working/train/giza.en-si/en-si.A3.final.gz" -i "pigz -cd /home/anuadmin/moses/working/train/giza.si-en/si-en.A3.final.gz" |/home/anuadmin/moses/mosesdecoder/scripts/../bin/symal -alignment="grow" -diagonal="yes" -final="yes" -both="yes" > /home/anuadmin/moses/working/train/model/aligned.grow-diag-final-and
symal: computing grow alignment: diagonal (1) final (1)both-uncovered (1)
Sentence mismatch error! Line #14464
skip=<0> counts=<45500>
(4) generate lexical translation table 0-0 @ Fri Nov 22 21:15:51 +0530 2019
(/home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.si,/home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.en,/home/anuadmin/moses/working/train/model/lex)
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
Saved: /home/anuadmin/moses/working/train/model/lex.f2e and /home/anuadmin/moses/working/train/model/lex.e2f
FILE: /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.en
FILE: /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.si
FILE: /home/anuadmin/moses/working/train/model/aligned.grow-diag-final-and
(5) extract phrases @ Fri Nov 22 21:16:52 +0530 2019
/home/anuadmin/moses/mosesdecoder/scripts/generic/extract-parallel.perl 2 split "sort    " /home/anuadmin/moses/mosesdecoder/scripts/../bin/extract /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.en /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.si /home/anuadmin/moses/working/train/model/aligned.grow-diag-final-and /home/anuadmin/moses/working/train/model/extract 7 orientation --model wbe-msd --GZOutput 
Executing: /home/anuadmin/moses/mosesdecoder/scripts/generic/extract-parallel.perl 2 split "sort    " /home/anuadmin/moses/mosesdecoder/scripts/../bin/extract /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.en /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.si /home/anuadmin/moses/working/train/model/aligned.grow-diag-final-and /home/anuadmin/moses/working/train/model/extract 7 orientation --model wbe-msd --GZOutput 
MAX 7 1 0
Started Fri Nov 22 21:16:52 2019
using pigz 
isBSDSplit=0 
Executing: mkdir -p /home/anuadmin/moses/working/train/model/tmp.5618; ls -l /home/anuadmin/moses/working/train/model/tmp.5618 
total=45500 line-per-split=22751 
split -d -l 22751 -a 7 /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.si /home/anuadmin/moses/working/train/model/tmp.5618/source.split -d -l 22751 -a 7 /home/anuadmin/moses/corpus/locations/si-en/data.si-en.clean.en /home/anuadmin/moses/working/train/model/tmp.5618/target.split -d -l 22751 -a 7 /home/anuadmin/moses/working/train/model/aligned.grow-diag-final-and /home/anuadmin/moses/working/train/model/tmp.5618/align.merging extract / extract.inv
gunzip -c /home/anuadmin/moses/working/train/model/tmp.5618/extract.0000000.o.gz /home/anuadmin/moses/working/train/model/tmp.5618/extract.0000001.o.gz  | LC_ALL=C sort     -T /home/anuadmin/moses/working/train/model/tmp.5618 2>> /dev/stderr | pigz -c > /home/anuadmin/moses/working/train/model/extract.o.sorted.gz 2>> /dev/stderr 
gunzip -c /home/anuadmin/moses/working/train/model/tmp.5618/extract.0000000.inv.gz /home/anuadmin/moses/working/train/model/tmp.5618/extract.0000001.inv.gz  | LC_ALL=C sort     -T /home/anuadmin/moses/working/train/model/tmp.5618 2>> /dev/stderr | pigz -c > /home/anuadmin/moses/working/train/model/extract.inv.sorted.gz 2>> /dev/stderr 
gunzip -c /home/anuadmin/moses/working/train/model/tmp.5618/extract.0000000.gz /home/anuadmin/moses/working/train/model/tmp.5618/extract.0000001.gz  | LC_ALL=C sort     -T /home/anuadmin/moses/working/train/model/tmp.5618 2>> /dev/stderr | pigz -c > /home/anuadmin/moses/working/train/model/extract.sorted.gz 2>> /dev/stderr 
Finished Fri Nov 22 21:20:03 2019
(6) score phrases @ Fri Nov 22 21:20:03 +0530 2019
(6.1)  creating table half /home/anuadmin/moses/working/train/model/phrase-table.half.f2e @ Fri Nov 22 21:20:03 +0530 2019
/home/anuadmin/moses/mosesdecoder/scripts/generic/score-parallel.perl 2 "sort    " /home/anuadmin/moses/mosesdecoder/scripts/../bin/score /home/anuadmin/moses/working/train/model/extract.sorted.gz /home/anuadmin/moses/working/train/model/lex.f2e /home/anuadmin/moses/working/train/model/phrase-table.half.f2e.gz  0 
Executing: /home/anuadmin/moses/mosesdecoder/scripts/generic/score-parallel.perl 2 "sort    " /home/anuadmin/moses/mosesdecoder/scripts/../bin/score /home/anuadmin/moses/working/train/model/extract.sorted.gz /home/anuadmin/moses/working/train/model/lex.f2e /home/anuadmin/moses/working/train/model/phrase-table.half.f2e.gz  0 
using pigz 
Started Fri Nov 22 21:20:03 2019
/home/anuadmin/moses/mosesdecoder/scripts/../bin/score /home/anuadmin/moses/working/train/model/tmp.5676/extract.0.gz /home/anuadmin/moses/working/train/model/lex.f2e /home/anuadmin/moses/working/train/model/tmp.5676/phrase-table.half.0000000.gz  2>> /dev/stderr 
/home/anuadmin/moses/working/train/model/tmp.5676/run.1.sh/home/anuadmin/moses/working/train/model/tmp.5676/run.0.shmv /home/anuadmin/moses/working/train/model/tmp.5676/phrase-table.half.0000000.gz /home/anuadmin/moses/working/train/model/phrase-table.half.f2e.gzrm -rf /home/anuadmin/moses/working/train/model/tmp.5676 
Finished Fri Nov 22 21:21:42 2019
(6.3)  creating table half /home/anuadmin/moses/working/train/model/phrase-table.half.e2f @ Fri Nov 22 21:21:42 +0530 2019
/home/anuadmin/moses/mosesdecoder/scripts/generic/score-parallel.perl 2 "sort    " /home/anuadmin/moses/mosesdecoder/scripts/../bin/score /home/anuadmin/moses/working/train/model/extract.inv.sorted.gz /home/anuadmin/moses/working/train/model/lex.e2f /home/anuadmin/moses/working/train/model/phrase-table.half.e2f.gz --Inverse 1 
Executing: /home/anuadmin/moses/mosesdecoder/scripts/generic/score-parallel.perl 2 "sort    " /home/anuadmin/moses/mosesdecoder/scripts/../bin/score /home/anuadmin/moses/working/train/model/extract.inv.sorted.gz /home/anuadmin/moses/working/train/model/lex.e2f /home/anuadmin/moses/working/train/model/phrase-table.half.e2f.gz --Inverse 1 
using pigz 
Started Fri Nov 22 21:21:43 2019
/home/anuadmin/moses/mosesdecoder/scripts/../bin/score /home/anuadmin/moses/working/train/model/tmp.5699/extract.0.gz /home/anuadmin/moses/working/train/model/lex.e2f /home/anuadmin/moses/working/train/model/tmp.5699/phrase-table.half.0000000.gz --Inverse  2>> /dev/stderr 
/home/anuadmin/moses/working/train/model/tmp.5699/run.1.sh/home/anuadmin/moses/working/train/model/tmp.5699/run.0.shgunzip -c /home/anuadmin/moses/working/train/model/tmp.5699/phrase-table.half.*.gz 2>> /dev/stderr| LC_ALL=C sort     -T /home/anuadmin/moses/working/train/model/tmp.5699  | pigz -c > /home/anuadmin/moses/working/train/model/phrase-table.half.e2f.gz  2>> /dev/stderr rm -rf /home/anuadmin/moses/working/train/model/tmp.5699 
Finished Fri Nov 22 21:23:34 2019
(6.6) consolidating the two halves @ Fri Nov 22 21:23:34 +0530 2019
Executing: /home/anuadmin/moses/mosesdecoder/scripts/../bin/consolidate /home/anuadmin/moses/working/train/model/phrase-table.half.f2e.gz /home/anuadmin/moses/working/train/model/phrase-table.half.e2f.gz /dev/stdout | pigz -c > /home/anuadmin/moses/working/train/model/phrase-table.gz
Consolidate v2.0 written by Philipp Koehn
consolidating direct and indirect rule tables
.
Executing: rm -f /home/anuadmin/moses/working/train/model/phrase-table.half.*
(7) learn reordering model @ Fri Nov 22 21:24:13 +0530 2019
(7.1) [no factors] learn reordering model @ Fri Nov 22 21:24:13 +0530 2019
(7.2) building tables @ Fri Nov 22 21:24:13 +0530 2019
Executing: /home/anuadmin/moses/mosesdecoder/scripts/../bin/lexical-reordering-score /home/anuadmin/moses/working/train/model/extract.o.sorted.gz 0.5 /home/anuadmin/moses/working/train/model/reordering-table. --model "wbe msd wbe-msd-bidirectional-fe"
Lexical Reordering Scorer
scores lexical reordering models of several types (hierarchical, phrase-based and word-based-extraction
(8) learn generation model @ Fri Nov 22 21:24:53 +0530 2019
  no generation model requested, skipping step
(9) create moses.ini @ Fri Nov 22 21:24:53 +0530 2019
